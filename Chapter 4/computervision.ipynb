{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the following steps to set up an Azure Computer Vision service. In this chapter, we will use the [Azure CLI a lot to create and delete our resources](https://docs.microsoft.com/en-us/azure/cognitive-services/cognitive-services-apis-create-account-cli?tabs=linux). Cognitive Service you setup, then you might be asked to provision the service using the Azure Portal as you need to accept the Responsible AI terms. You will likely see this error message:\n",
    "```\n",
    "This subscription cannot create ComputerVision until you agree to Responsible AI terms for this resource. You can agree to Responsible AI terms by creating a resource through the Azure Portal then trying again. For more detail go to https://go.microsoft.com/fwlink/?linkid=2164911\n",
    "```\n",
    "First, perform a login according to step 1. As you may have more than one subscriptions in your directory, we set the standard subscription that Azure CLI will use in 2. Finally, there are individual setup and destroy scripts for each service.\n",
    "\n",
    "1. `az login`\n",
    "2. `az account set --subscription \"<YOUR SUBSCRIPTION ID>\"`\n",
    "3. `./computervision-setup.sh`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cognitive Services Computer Vision\n",
    "\n",
    "- [Azure-Samples Quickstart code](https://github.com/Azure-Samples/cognitive-services-quickstart-code)\n",
    "- [Azure Cognitive Services Computer Vision SDK for Python](https://docs.microsoft.com/en-us/python/api/overview/azure/cognitiveservices-vision-computervision-readme?view=azure-python)\n",
    "\n",
    "ðŸŸ¥ As Python is the de facto standard language in Machine Learning we will make use of it in most cases. To see other SDK in other languages, please refer to Azure-Samples Quickstart code repository (see above)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OCR Text recognition\n",
    "\n",
    "- [OCR Quickstart](https://docs.microsoft.com/en-us/azure/cognitive-services/computer-vision/quickstarts-sdk/client-library?tabs=visual-studio&pivots=programming-language-python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
    "from azure.cognitiveservices.vision.computervision.models import OperationStatusCodes\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "region = os.environ[\"ACCOUNT_REGION\"]\n",
    "key = os.environ[\"ACCOUNT_KEY\"]\n",
    "\n",
    "credentials = CognitiveServicesCredentials(key)\n",
    "client = ComputerVisionClient(\n",
    "    endpoint=\"https://\" + region + \".api.cognitive.microsoft.com/\",\n",
    "    credentials=credentials\n",
    ")\n",
    "\n",
    "# set link if you like to use your own image\n",
    "url = \"https://github.com/Azure-Samples/cognitive-services-python-sdk-samples/raw/master/samples/vision/images/make_things_happen.jpg\"\n",
    "raw = True\n",
    "numberOfCharsInOperationId = 36\n",
    "\n",
    "# SDK call\n",
    "rawHttpResponse = client.read(url, language=\"en\", raw=True)\n",
    "\n",
    "# Get ID from returned headers\n",
    "operation_location = rawHttpResponse.headers[\"Operation-Location\"]\n",
    "id_location = len(operation_location) - numberOfCharsInOperationId\n",
    "operation_id = operation_location[id_location:]\n",
    "\n",
    "# Call the \"GET\" API and wait for it to retrieve the results \n",
    "while True:\n",
    "    result = client.get_read_result(operation_id)\n",
    "    if result.status not in ['notStarted', 'running']:\n",
    "        break\n",
    "    time.sleep(1)\n",
    "\n",
    "# Get data\n",
    "if result.status == OperationStatusCodes.succeeded:\n",
    "\n",
    "    for line in result.analyze_result.read_results[0].lines:\n",
    "        print(line.text)\n",
    "        print(line.bounding_box)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image understanding\n",
    "\n",
    "- https://docs.microsoft.com/en-us/python/api/overview/azure/cognitiveservices-vision-computervision-readme?view=azure-python#analyze-an-image\n",
    "\n",
    "In this example we want to analyze an image by tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'additional_properties': {}, 'name': 'building', 'confidence': 0.9917298555374146, 'hint': None}\n",
      "{'additional_properties': {}, 'name': 'metropolis', 'confidence': 0.9371380805969238, 'hint': None}\n",
      "{'additional_properties': {}, 'name': 'metropolitan area', 'confidence': 0.9317947626113892, 'hint': None}\n",
      "{'additional_properties': {}, 'name': 'downtown', 'confidence': 0.928309440612793, 'hint': None}\n",
      "{'additional_properties': {}, 'name': 'skyscraper', 'confidence': 0.9235161542892456, 'hint': None}\n",
      "{'additional_properties': {}, 'name': 'outdoor', 'confidence': 0.9170207977294922, 'hint': None}\n",
      "{'additional_properties': {}, 'name': 'urban area', 'confidence': 0.913856029510498, 'hint': None}\n",
      "{'additional_properties': {}, 'name': 'street', 'confidence': 0.8924431204795837, 'hint': None}\n",
      "{'additional_properties': {}, 'name': 'commercial building', 'confidence': 0.8783712387084961, 'hint': None}\n",
      "{'additional_properties': {}, 'name': 'crowded', 'confidence': 0.8758255243301392, 'hint': None}\n",
      "{'additional_properties': {}, 'name': 'mixed-use', 'confidence': 0.8670334815979004, 'hint': None}\n",
      "{'additional_properties': {}, 'name': 'night', 'confidence': 0.8203572034835815, 'hint': None}\n",
      "{'additional_properties': {}, 'name': 'city', 'confidence': 0.8055667877197266, 'hint': None}\n",
      "{'additional_properties': {}, 'name': 'people', 'confidence': 0.6955504417419434, 'hint': None}\n",
      "{'additional_properties': {}, 'name': 'light', 'confidence': 0.6881226301193237, 'hint': None}\n"
     ]
    }
   ],
   "source": [
    "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
    "from azure.cognitiveservices.vision.computervision.models import VisualFeatureTypes\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "\n",
    "import os\n",
    "region = os.environ['ACCOUNT_REGION']\n",
    "key = os.environ['ACCOUNT_KEY']\n",
    "\n",
    "credentials = CognitiveServicesCredentials(key)\n",
    "client = ComputerVisionClient(\n",
    "    endpoint=\"https://\" + region + \".api.cognitive.microsoft.com/\",\n",
    "    credentials=credentials\n",
    ")\n",
    "\n",
    "# set link if you like to use your own image\n",
    "url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/1/12/Broadway_and_Times_Square_by_night.jpg/450px-Broadway_and_Times_Square_by_night.jpg\"\n",
    "\n",
    "image_analysis = client.analyze_image(url, visual_features=[VisualFeatureTypes.tags])\n",
    "\n",
    "for tag in image_analysis.tags:\n",
    "    print(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
